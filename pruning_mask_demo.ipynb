{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0428a47c-c751-440f-b3d9-982fc51974a3",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaf352c-e9f7-4f98-8869-5b6b5834b95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from modules_demo import models\n",
    "from matplotlib import pyplot as plt\n",
    "import copy\n",
    "import pickle as pkl\n",
    "\n",
    "# set only the specified GPUs as \"available\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"7\"\n",
    "\n",
    "# set a seed\n",
    "SEED = 5435"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4affedf-d529-416e-9df1-1187af4e2a80",
   "metadata": {},
   "source": [
    "### Set SEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bc4634-96a9-4956-9341-0c46f4728da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seeds for reproducible results\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# prepare GPU\n",
    "physical_gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if physical_gpus:\n",
    "    try:\n",
    "        for _gpu in physical_gpus:\n",
    "            tf.config.experimental.set_memory_growth(_gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "print('number of Logical GPUs:', len(logical_gpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788adeee-c184-4717-931d-66405ed473ac",
   "metadata": {},
   "source": [
    "## Hyper-Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd2224a-0f2e-4d86-859c-7919cc986a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight of the crossentropy(H) inside the loss function\n",
    "# loss = loss_weight*H + (1-loss_weight)*regularization_term\n",
    "# The final pruning intensity is stricktly linked to the loss_weight:\n",
    "# the lower the strongher the pruning.\n",
    "loss_weight = 0.1\n",
    "\n",
    "# threshold used to binarize both the probability masks at inferce time:\n",
    "threshold_to_binarize_mask_values = 0.5\n",
    "\n",
    "# Used at training time by the loss \"Mask_lp_distance_from_binary\"\n",
    "# to promote (values close to 1) or not (values close to 0.5) the\n",
    "# final binarization and pruning strength of the probability masks\n",
    "regularization_binarizer = 0.9\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# Max number of epochs allowed before training stops \n",
    "# (Early Stop terminates the training if it converges)\n",
    "# if 0 the training is skipped\n",
    "# train the model without the pruning masks\n",
    "max_epochs_initial_train = 0\n",
    "\n",
    "# pruning training (both weights and masks)\n",
    "max_epochs_pruning_train = 1000\n",
    "# for \"one-step-train\" set 0 and 1000\n",
    "# for \"two-step-train\" set 1000 and 1000\n",
    "\n",
    "# corresponding learning rate\n",
    "# we suggest to use a lower lr for the pruning train, e.g., 10x lower\n",
    "learning_rate_initial_train = 1e-3\n",
    "learning_rate_pruning_train = 1e-4\n",
    "\n",
    "# where to save the model weights, if None: skip savings\n",
    "weights_path = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94663c38-43b0-4aa8-83af-520abb81dfbb",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d907df-05d5-479a-a415-f0f3abe6e912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cifar100\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar100.load_data()\n",
    "\n",
    "# hot labeling\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 100)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 100)\n",
    "\n",
    "# create validation set\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "        x_train,\n",
    "        y_train, \n",
    "        test_size=0.2, \n",
    "        random_state=SEED,\n",
    "    )\n",
    "\n",
    "# augment the size of the images\n",
    "new_image_shape = (224, 224)\n",
    "\n",
    "to_my_tensor_x = lambda x: tf.image.resize(\n",
    "                            tf.convert_to_tensor(x),\n",
    "                            new_image_shape)\n",
    "\n",
    "# create tensors\n",
    "x_train = to_my_tensor_x(x_train)\n",
    "x_val = to_my_tensor_x(x_val)\n",
    "x_test = to_my_tensor_x(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a7b7c3-891c-4d71-aa41-21a63be4d314",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Retrieve model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d58f4a-9952-4c0f-87d8-e62e630b9582",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = np.shape(x_train[0])\n",
    "\n",
    "# retrieve AlexNet\n",
    "model = models.model_AlexNet(\n",
    "        input_shape,\n",
    "    )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c7d17c-0fd3-4874-9ce2-d1a082f6c76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the number of weights of the model\n",
    "# only the trainable weights: \"model.trainable_weights\"\n",
    "w_tmp_list = model.weights\n",
    "tot_par_init = 0\n",
    "for w_tmp in w_tmp_list:\n",
    "    par_tmp = 1\n",
    "    for shape_tmp in np.shape(w_tmp):\n",
    "        par_tmp = par_tmp * shape_tmp\n",
    "    tot_par_init = tot_par_init + par_tmp\n",
    "print(f'Number of weights of the model BEFORE PRUNING: {tot_par_init}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb41e82e-b068-4be9-a71b-3ad88d467e27",
   "metadata": {},
   "source": [
    "### Prepare model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c8cd33-b2ea-4c0f-add8-1bbca5706db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate_initial_train),\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy(),\n",
    "        metrics = ['accuracy'],\n",
    "    )\n",
    "\n",
    "callback_list=[\n",
    "        tf.keras.callbacks.TerminateOnNaN(), \n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                monitor='val_loss',\n",
    "                factor = 0.2,\n",
    "                patience = 40,\n",
    "                min_lr = 10e-6,\n",
    "            ),\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                patience=100,\n",
    "                restore_best_weights=True,\n",
    "            ),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d02bd04-7b87-42ae-be2a-0faf6a6aff83",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec69282-244c-4ede-b224-72d209619849",
   "metadata": {},
   "outputs": [],
   "source": [
    "if max_epochs_initial_train > 0:\n",
    "    model.fit(\n",
    "            x = x_train,\n",
    "            y = y_train,\n",
    "            callbacks=callback_list,\n",
    "            validation_data=(x_val, y_val),\n",
    "            batch_size=batch_size,\n",
    "            epochs=max_epochs_initial_train,\n",
    "            verbose=2,\n",
    "         );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88255293-7543-4af0-9b90-fca6e8d6c1e0",
   "metadata": {},
   "source": [
    "### Model performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb25c90-ba5d-404b-b2b1-8880004998df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evaluate = model.evaluate(x_test, y_test, batch_size = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67effc50-834c-4910-81ba-33ff892accc9",
   "metadata": {},
   "source": [
    "# Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023f3694-5c5b-4e28-ae83-7f59e23df71f",
   "metadata": {},
   "source": [
    "## Prepare model for pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a61fb5-8c07-4f7d-8c96-32c952c449e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a \"Model_for_pruning\" instance. This class inherits the tf.keras.Model\n",
    "# class and adds some functionalities necessary to handle the pruning train.\n",
    "# The functino adds the \"mask layers\" to the model:\n",
    "# each Dense layer in the model, apart the outout layer, is coupled with\n",
    "# a binary mask that can be trained. The zeros of the binary masks\n",
    "# indicate what neurons are pruned, while the ones indicate what are saved.\n",
    "model_pruning = models.add_mask_pruning(\n",
    "        model = model,\n",
    "        model_name = 'model_pruning',\n",
    "    )\n",
    "\n",
    "# Notice that now the model is composed by \"Functional\" layers.\n",
    "# Under the hood a \"Functiional\" is a tf.keras.Model, used as a layer.\n",
    "# The Functional named \"sub_model\" contains the part of the original model\n",
    "# layers, also its last layer is a Dense layer.\n",
    "# Every \"sub_model\" is followed by a Functional \"pruning_mask\", that \n",
    "# takes as input the output of the previous sub_model'dense'output to create\n",
    "# a trainable binary mask that has the same dimension and \n",
    "# to multiply element-wise the input with the mask (mask apply pruning).\n",
    "# All but the last sub_model are followed by a mask. The output, in general,\n",
    "# cannot be pruned. \n",
    "# Also another output is introduced: the concatenation of the prob_masks. This\n",
    "# is created by the Functional \"model_concatenate_mask\" that takes all the\n",
    "# prob_masks and concatenate them together. This output is used as input for \n",
    "# the regularization term, to reduce regulate the number of 1s/0s in the \n",
    "# final masks, hence to decide the intensity of the pruning.\n",
    "model_pruning.summary(expand_nested=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb95470-915a-4a23-9704-8d995748c420",
   "metadata": {},
   "source": [
    "### Dataset for Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d28a2a4-4b1f-48d9-a09d-b659af4071dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the addition of a new output requires to change the dataset: \n",
    "# a new label (for the second output) is to be given to the model.\n",
    "# In reality, the new label will be useless, it fact the regularization\n",
    "# term does not require it. For this reason we create a fake label.\n",
    "# To the already existsing labels we couple a fake one.\n",
    "zeros = lambda y: np.zeros((len(y), ) + model_pruning.outputs[1].shape[1:])\n",
    "    \n",
    "[y_train_fit,\n",
    " y_val_fit,\n",
    " y_test_fit,] = [\n",
    "    [y, zeros(y)]\n",
    "    for y \n",
    "    in [y_train, y_val, y_test]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b85d711-bef4-4963-9673-635381b5cbe9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3efc7b7f-f9f8-448d-9d6c-bef22b1a6c2d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Random Mask Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5363067e-02d9-4830-b778-d04867a752a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly initialize the mask so that the prob_mask has samples drawn\n",
    "# from a gaussian distribution. The initialization slightly influences\n",
    "# the final performances. However, it can modify the final pruning intensity.\n",
    "init_prob_masks = np.random.normal(\n",
    "        0.5, \n",
    "        0.1,\n",
    "        np.shape(model_pruning.read_prob_masks()),\n",
    "    )\n",
    "\n",
    "# values of prob_mask must be inside the range [0, 1]\n",
    "init_prob_masks = np.clip(init_prob_masks, 0.00001, 0.9999)\n",
    "model_pruning.write_prob_masks(init_prob_masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a096d35-56db-41f7-af12-cb929c285907",
   "metadata": {},
   "source": [
    "### Prepare for Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40465676-307a-4351-8d02-32a0e13ebb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Mask_lp_distance_from_binary(threshold = 0.5, p = 2, name = 'pruning'):\n",
    "    \n",
    "    class Loss_Mask_lp_distance_from_binary(tf.keras.losses.Loss):\n",
    "        \n",
    "        \"\"\"\n",
    "        Regularization term used to binarize the prob_mask,\n",
    "        it promotes the mask to have values close to 0 or 1. The higher \n",
    "        \"threshold\" the more the 0s in the prob_mask.\n",
    "        \n",
    "        regularization = -mean(|mask-threshold|**p)\n",
    "        \n",
    "        Args:\n",
    "            threshold: float in ]0.5, 1[, the value from where the mask\n",
    "                samples are pushed away.\n",
    "            p: Int, the norm degree\n",
    "            name: String, the norm of the loss\n",
    "        \"\"\"\n",
    "        \n",
    "        def call(self, _, y_pred):\n",
    "            diff = tf.math.abs(y_pred - self.threshold)\n",
    "            diff = tf.pow(diff, tf.ones(tf.shape(y_pred)) * self.p)\n",
    "            measured_sparsity = -tf.keras.backend.mean(diff)\n",
    "            return measured_sparsity\n",
    "\n",
    "        def set_attributes(self, threshold = 0.5, p = 2):\n",
    "            self.threshold = threshold\n",
    "            self.p = p\n",
    "            return\n",
    "    \n",
    "    loss = Loss_Mask_lp_distance_from_binary(name = name)\n",
    "    loss.set_attributes(threshold, p)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc5f793-5a62-454d-896d-c9756217234d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = loss_weight*crossentropy + (1-loss_weight)*regularization_term\n",
    "loss = [[tf.keras.losses.CategoricalCrossentropy(name = 'entropy')],\n",
    "        [Mask_lp_distance_from_binary(\n",
    "            threshold = regularization_binarizer, \n",
    "            name = 'loss_pruning',\n",
    "        )],\n",
    "       ]\n",
    "\n",
    "# to visualize the accuracy during training\n",
    "metrics = [['accuracy',],\n",
    "           [],\n",
    "         ]\n",
    "\n",
    "regularization_weight = 1 - loss_weight\n",
    "\n",
    "loss_weights = [\n",
    "        loss_weight,\n",
    "        regularization_weight\n",
    "    ]\n",
    "\n",
    "# setting a lower learning rate helps the convergence of the masks\n",
    "model_pruning.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(\n",
    "            learning_rate=learning_rate_pruning_train,\n",
    "        ),\n",
    "    loss = loss,\n",
    "    metrics = metrics,\n",
    "    loss_weights = loss_weights,\n",
    "   )\n",
    "\n",
    "callback_pruning_list=[\n",
    "        tf.keras.callbacks.TerminateOnNaN(), \n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                monitor='val_loss',\n",
    "                factor = 0.2,\n",
    "                patience = 40,\n",
    "                min_lr = 1e-6,\n",
    "            ),\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                patience=100,\n",
    "                restore_best_weights=True,\n",
    "            ),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6d050a-e207-46c2-bd1b-654a4717addc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before trainig, be sure to call these methods:\n",
    "# by setting verbose = True, all the interested layer names are printed.\n",
    "verbose = False\n",
    "\n",
    "# Be sure that pruning is \"on\". \n",
    "model_pruning.activate_pruning(verbose = verbose)\n",
    "# Turn the mask trainable by disabling the binarization\n",
    "# and by activating the stochastic behavior.\n",
    "model_pruning.set_model_for_training(verbose = verbose)\n",
    "# set masks layers attribute \"trainable = True\"\n",
    "model_pruning.set_mask_trainability(mask_trainability = True,\n",
    "                                    verbose = verbose)\n",
    "# set all the original layers attribute \"trainable = True\"\n",
    "model_pruning.set_normal_layers_trainability(True, verbose = verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb8ce3f-48be-492b-9054-92c821d91cef",
   "metadata": {},
   "source": [
    "## Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805ce4af-da80-4b28-8efa-8e232191b262",
   "metadata": {},
   "outputs": [],
   "source": [
    "if max_epochs_pruning_train > 0:\n",
    "    model_pruning.fit(\n",
    "            x_train,\n",
    "            y_train_fit,\n",
    "            callbacks=callback_pruning_list,\n",
    "            validation_data=(x_val, y_val_fit),\n",
    "            batch_size=batch_size,\n",
    "            epochs=max_epochs_pruning_train,\n",
    "            verbose=2,\n",
    "        )\n",
    "    \n",
    "    # save weights\n",
    "    if weights_path is not None:\n",
    "        model_pruning.save_weights(weights_path);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d25dfa-a2ad-497e-90b4-bd163ed7d344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the weights of the model\n",
    "if weights_path is not None:\n",
    "    model_pruning.load_weights(weights_path);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fab8640-846f-4110-bfc1-ddbce5c3bcc5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28a8879-c1fd-4152-aafc-accedd2750be",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruning_training_evaluate = model_pruning.evaluate(\n",
    "        x_test,\n",
    "        y_test_fit,\n",
    "        batch_size = 100,\n",
    "    );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0411918-90fb-41dd-901b-62312e0e5bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable the stocharstic behavior of the mask, that becomes fixed\n",
    "# and binarize the mask with a threshold_value in [0, 1]\n",
    "model_pruning.set_model_for_inference(\n",
    "        minval = threshold_to_binarize_mask_values-0.0001,\n",
    "        maxval = threshold_to_binarize_mask_values+0.0001,\n",
    "        verbose = verbose,\n",
    "    )\n",
    "\n",
    "pruning_evaluate = model_pruning.evaluate(\n",
    "        x_test,\n",
    "        y_test_fit,\n",
    "        batch_size = 100,\n",
    "    );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a27c2e-3ce4-4819-b32a-cb8e9911c2fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887f07cc-c488-477c-8be0-172e0986a967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the prob_masks\n",
    "prob_masks = model_pruning.read_prob_masks()\n",
    "\n",
    "# get a mask realization.\n",
    "# if the model is in \"infecerence mode\" the mask is fixed and the \n",
    "# result is unique. If the model is in \"training mode\", the inference masks\n",
    "# may vary.\n",
    "inference_masks = model_pruning.read_inference_masks(\n",
    "        threshold_value = 0.5,\n",
    "        minval = threshold_to_binarize_mask_values-0.0001,\n",
    "        maxval = threshold_to_binarize_mask_values+0.0001,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524478a5-642d-4334-a280-1f6fc76c59db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for visualization purposes we reshape the masks as a square matrix\n",
    "mask_reshape = (64, 64)\n",
    "\n",
    "[init_prob_masks_plot, prob_masks_plot, inference_masks_plot] = [\n",
    "        [\n",
    "            np.reshape(p, mask_reshape)\n",
    "            for p\n",
    "            in m\n",
    "        ]\n",
    "        for m\n",
    "        in [ init_prob_masks, prob_masks, inference_masks]\n",
    "    ]\n",
    "\n",
    "# every i-th column shows the masks associated with dense layer i-th\n",
    "fig, axss = plt.subplots(3, len(prob_masks))\n",
    "fig.set_figheight(10)\n",
    "for axs, mask_tmp, title in zip(axss, \n",
    "                         [init_prob_masks_plot, \n",
    "                          prob_masks_plot,\n",
    "                          inference_masks_plot],\n",
    "                         ['initial random prob_mask',\n",
    "                          'trained prob mask',\n",
    "                          'final mask realization'],\n",
    "                        ):\n",
    "    \n",
    "    for i, (ax, m) in enumerate(zip(axs, mask_tmp)):\n",
    "        \n",
    "        ax.imshow(m, cmap = 'gray', vmin = 0, vmax = 1)\n",
    "        ax.title.set_text(title)\n",
    "\n",
    "plt.show()\n",
    "# the mean of the masks is the average number of pruned neurons\n",
    "print(f'masks mean = {np.mean(prob_masks)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b0137a-4e63-4a6b-8558-2edba36d61b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The histogram of the prob mask shows how much the prob mask is binarized.\n",
    "# In general, the more it is binary, the higher the performances, but the fewer\n",
    "# the possible levels of pruning one can obtain by varying the threshold that\n",
    "# binarizes the mask\n",
    "plt.hist(np.ravel(prob_masks_plot), 100);\n",
    "plt.title('histogram all of prob masks')\n",
    "plt.xlabel('bins')\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9068e07-5c5d-4dbf-8060-06a8d18eeb34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e160ef-867f-4f86-8b59-d4b03e46356f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f'initial model acc = {model_evaluate[1]*100}%',\n",
    "    f'\\npruning model acc = {pruning_evaluate[3]*100}%',\n",
    "    f'\\n\\n% of remaining neurons = {100*np.mean(inference_masks)}%',\n",
    "    f'\\n% of pruned neurons = {100-100*np.mean(inference_masks)}%',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b38294-e7cf-4ca2-8b5e-6ac4f0f5e6f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0e5926f-b4fa-4053-a6fa-41320cd9c9ba",
   "metadata": {},
   "source": [
    "# Pruned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f64926-4345-4e77-9dd6-a9155660d01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the pruned model, that does not have the mask layers\n",
    "# any more, and the Dense layers have been pruned (only the neurons\n",
    "# corresponding to the 1s in the masks are kept, along with \n",
    "# their weights).\n",
    "model_pruned = model_pruning.return_pruned_model(\n",
    "        minval = threshold_to_binarize_mask_values - 0.0001,\n",
    "        maxval = threshold_to_binarize_mask_values + 0.0001,\n",
    "        model_name = 'pruned_model',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4b83b5-f9f3-4b6e-b8f3-c5009fd5a809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice the model is identical to the original one, but \n",
    "# the number of parameters has been lowered (if the masks contained\n",
    "# at least one 0)\n",
    "model_pruned.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9504e5b4-a234-4b83-8cd9-16ab2b5dce62",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pruned.compile(\n",
    "        optimizer = tf.keras.optimizers.Adam(),\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy(),\n",
    "        metrics = ['accuracy'],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64250f96-a485-4e43-ab78-f85395c8e72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pruned_evaluate = model_pruned.evaluate(\n",
    "        x_test,\n",
    "        y_test,\n",
    "        batch_size = 100,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6daf7b6-c0f2-4993-b8f3-cb973145b575",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f'initial model acc = {model_evaluate[1]*100}%',\n",
    "    f'\\npruning model acc = {pruning_evaluate[3]*100}%',\n",
    "    f'\\npruned model acc = {model_pruned_evaluate[1]*100}%',\n",
    "    \n",
    "    f'\\n\\n% of remaining neurons = {100*np.mean(inference_masks)}%',\n",
    "    f'\\n% of pruned neurons = {100-100*np.mean(inference_masks)}%',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a656751-951e-47de-8e50-8b2cb5b06068",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'results.pkl' \n",
    "file_name = 'for_sujuk.pkl'\n",
    "    \n",
    "try:\n",
    "    with open(file_name, 'rb') as f:\n",
    "        results = pkl.load(f)\n",
    "except:\n",
    "    results = []\n",
    "        \n",
    "\n",
    "update_results = True\n",
    "for r in results:\n",
    "    if r['weights_path'] == weights_path:\n",
    "        update_results = False\n",
    "\n",
    "if update_results == True:\n",
    "    \n",
    "    new_results = {\n",
    "        'param_removed_list': param_removed_list,\n",
    "        'top_1_list': top_1_list,\n",
    "        'loss_weight': loss_weight,\n",
    "        'threshold_to_binarize_mask_values': threshold_to_binarize_mask_values,\n",
    "        'regularization_binarizer': regularization_binarizer,\n",
    "        'weights_path': weights_path,\n",
    "    }\n",
    "    \n",
    "    results += [new_results]\n",
    "    with open(file_name, 'wb') as f:\n",
    "        pkl.dump(results, f)\n",
    "\n",
    "        print('results updated')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8061c9b9-7545-4f58-b7b0-6d50bb95e5cd",
   "metadata": {},
   "source": [
    "## Further Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad446b96-3ac7-4697-9e4e-fd94217d4cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore \"accuracy\" and \"% of pruned neurons\" variations\n",
    "# by changing \"threshold_to_binarize_mask_values\" \n",
    "\n",
    "# all \"threshold_to_binarize_mask_values\" values to explore\n",
    "meanval_list = np.arange(-0.05, 1, 0.05)\n",
    "\n",
    "for meanval in meanval_list:\n",
    "    \n",
    "    maxval = meanval + 0.0001\n",
    "    minval = meanval - 0.0001\n",
    "    \n",
    "    # create a pruned model based on prob_masks > meanval\n",
    "    model_tmp = model_pruning.return_pruned_model(\n",
    "            minval = minval,\n",
    "            maxval = maxval,\n",
    "            model_name = 'pruned_model',\n",
    "        )\n",
    "    \n",
    "    # compile before running \"evaluate\"\n",
    "    model_tmp.compile(\n",
    "            optimizer = tf.keras.optimizers.Adam(),\n",
    "            loss = tf.keras.losses.CategoricalCrossentropy(),\n",
    "            metrics = ['accuracy'],\n",
    "        )\n",
    "    \n",
    "    # read the inference masks to compute the % of pruned parameters\n",
    "    inference_masks = model_pruning.read_inference_masks(\n",
    "            threshold_value = 0.5,\n",
    "            minval = minval,\n",
    "            maxval = maxval,\n",
    "            silence_alert = True,\n",
    "        )\n",
    "    \n",
    "    # find accuracy of the pruned model\n",
    "    evaluate_tmp = model_tmp.evaluate(\n",
    "            x_test,\n",
    "            y_test,\n",
    "            batch_size = 100,\n",
    "            verbose = False,\n",
    "        )\n",
    "\n",
    "    \n",
    "    # find the number of weights of the pruned model\n",
    "    w_tmp_list = model_tmp.weights\n",
    "    tot_par_tmp = 0\n",
    "    for w_tmp in w_tmp_list:\n",
    "        par_tmp = 1\n",
    "        for shape_tmp in np.shape(w_tmp):\n",
    "            par_tmp = par_tmp * shape_tmp\n",
    "        tot_par_tmp = tot_par_tmp + par_tmp\n",
    "    \n",
    "    # compute the % of pruned parameters\n",
    "    percentage_pruned_param = (tot_par_init - tot_par_tmp)/tot_par_init*100\n",
    "    \n",
    "    print()\n",
    "    print(f'T = {meanval} --- accuracy top 1 = {np.round(evaluate_tmp[1]*100, 5)}%')\n",
    "    for i, m in enumerate(inference_masks):\n",
    "        print(f'{i+1}-th Dense layer mantained neurons: {np.sum(m)}')\n",
    "    print(f'-- % of pruned parameters = {np.round(percentage_pruned_param, 3)}%') \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee036050-dc9f-40a4-ab84-6d53581f1860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# at inference, one can move the threshold to obtain \n",
    "# models with different pruning intensities and different accuracy\n",
    "\n",
    "plt.plot(\n",
    "        100-np.array(param_removed_list)[np.argsort(top_1_list)],\n",
    "        np.array(top_1_list)[np.argsort(top_1_list)],\n",
    "        'x--',\n",
    "    )\n",
    "plt.xlabel('% of PRUNED parameters')\n",
    "plt.ylabel('accuracy top_1');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accf4535-c04e-4411-9a89-c770edf5f938",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
